{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AiqtcazO7l5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the entire dataset\n",
        "df = pd.read_csv('all-data.csv', encoding='ISO-8859-1', header=None, names=['sentiment', 'text'])\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the train and test sets to separate CSV files\n",
        "train_df.to_csv('train_data.csv', index=False)\n",
        "test_df.to_csv('test_data.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Read CSV file for training data with specified encoding\n",
        "train_df = pd.read_csv('train_data.csv', encoding='ISO-8859-1', header=None, names=['sentiment', 'text'])\n",
        "\n",
        "# Read CSV file for testing data with specified encoding\n",
        "test_df = pd.read_csv('test_data.csv', encoding='ISO-8859-1', header=None, names=['sentiment', 'text'])\n",
        "\n",
        "# Text Preprocessing\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove special characters and punctuation\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        return text\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply preprocessing to text data\n",
        "train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)\n",
        "test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)\n",
        "\n",
        "# Tokenization and Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def tokenize_and_lemmatize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Apply tokenization and lemmatization\n",
        "train_df['processed_text'] = train_df['cleaned_text'].apply(tokenize_and_lemmatize)\n",
        "test_df['processed_text'] = test_df['cleaned_text'].apply(tokenize_and_lemmatize)\n",
        "\n",
        "# Splitting the data\n",
        "X_train, y_train = train_df['processed_text'], train_df['sentiment']\n",
        "X_test, y_test = test_df['processed_text'], test_df['sentiment']\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Logistic Regression Model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "f1_score_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "print(\"F1 Score (Logistic Regression):\", f1_score_lr)\n",
        "\n",
        "# Print segment text along with sentiment analysis results\n",
        "# print(\"Segment Text\\t\\tActual\\t\\tPredicted\")\n",
        "# for segment, actual, predicted in zip(X_test, y_test, y_pred_lr):\n",
        "#     if actual == predicted:\n",
        "#         print(f\"\\033[92m{segment[:50] + '...' if len(segment) > 50 else segment}\\033[0m\", \"\\t\\t\", actual, \"\\t\\t\", predicted)\n",
        "#     else:\n",
        "#         print(segment[:50] + '...' if len(segment) > 50 else segment, \"\\t\\t\", actual, \"\\t\\t\", predicted)\n",
        "\n",
        "# Save the model and vectorizer\n",
        "joblib.dump(lr_model, 'sentiment_model.pkl')\n",
        "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n"
      ],
      "metadata": {
        "id": "79uOQElwtuSa",
        "outputId": "e9d94f63-abe0-4274-aecd-55028b280f5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (Logistic Regression): 0.7153917447111109\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate precision, recall, and F1 score for each class\n",
        "precision = precision_score(y_test, y_pred_lr, average=None, labels=['negative', 'neutral', 'positive'])\n",
        "recall = recall_score(y_test, y_pred_lr, average=None, labels=['negative', 'neutral', 'positive'])\n",
        "f1 = f1_score(y_test, y_pred_lr, average=None, labels=['negative', 'neutral', 'positive'])\n",
        "\n",
        "# Calculate weighted average of precision, recall, and F1 score\n",
        "weighted_precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
        "weighted_recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
        "weighted_f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "\n",
        "# Print precision, recall, and F1 score for each class\n",
        "print(\"Precision:\")\n",
        "for i, label in enumerate(['negative', 'neutral', 'positive']):\n",
        "    print(f\"{label.capitalize()}: {precision[i]}\")\n",
        "\n",
        "print(\"\\nRecall:\")\n",
        "for i, label in enumerate(['negative', 'neutral', 'positive']):\n",
        "    print(f\"{label.capitalize()}: {recall[i]}\")\n",
        "\n",
        "print(\"\\nF1 Score:\")\n",
        "for i, label in enumerate(['negative', 'neutral', 'positive']):\n",
        "    print(f\"{label.capitalize()}: {f1[i]}\")\n",
        "\n",
        "# Print weighted average of precision, recall, and F1 score\n",
        "print(\"\\nWeighted Average:\")\n",
        "print(\"Precision:\", weighted_precision)\n",
        "print(\"Recall:\", weighted_recall)\n",
        "print(\"F1 Score:\", weighted_f1)\n",
        "\n",
        "# Generate classification report and confusion matrix\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "id": "derzWPE9t4lu",
        "outputId": "e9935cbc-029e-48cf-c01a-dc32615f71db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7394438722966015\n",
            "Precision:\n",
            "Negative: 0.7741935483870968\n",
            "Neutral: 0.7278820375335121\n",
            "Positive: 0.7791411042944786\n",
            "\n",
            "Recall:\n",
            "Negative: 0.43636363636363634\n",
            "Neutral: 0.9509632224168126\n",
            "Positive: 0.43944636678200694\n",
            "\n",
            "F1 Score:\n",
            "Negative: 0.5581395348837209\n",
            "Neutral: 0.8246013667425969\n",
            "Positive: 0.5619469026548674\n",
            "\n",
            "Weighted Average:\n",
            "Precision: 0.7476351317150571\n",
            "Recall: 0.7394438722966015\n",
            "F1 Score: 0.7153917447111109\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.44      0.56       110\n",
            "     neutral       0.73      0.95      0.82       571\n",
            "    positive       0.78      0.44      0.56       289\n",
            "   sentiment       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.74       971\n",
            "   macro avg       0.57      0.46      0.49       971\n",
            "weighted avg       0.75      0.74      0.72       971\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 48  51  11   0]\n",
            " [  3 543  25   0]\n",
            " [ 11 151 127   0]\n",
            " [  0   1   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('microsoft-news_data.csv')  # Replace 'microsoft-news_data.csv' with the path to your CSV file\n",
        "\n",
        "# Extract the 'content' column as an array\n",
        "content_array = df['headlines'].values\n",
        "\n",
        "# Display the array\n",
        "# print(content_array)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "# Load NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Text Preprocessing functions\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Remove special characters and punctuation\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        return text\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Load the trained model and TF-IDF vectorizer\n",
        "lr_model = joblib.load('sentiment_model.pkl')\n",
        "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess the text segments\n",
        "cleaned_segments = [clean_text(segment) for segment in content_array]\n",
        "processed_segments = [remove_stopwords(segment) for segment in cleaned_segments]\n",
        "lemmatized_segments = [lemmatize_text(segment) for segment in processed_segments]\n",
        "\n",
        "# Vectorize the preprocessed text segments using the TF-IDF vectorizer\n",
        "text_tfidf = tfidf_vectorizer.transform(lemmatized_segments)\n",
        "\n",
        "# Predict the sentiment for each vectorized text segment\n",
        "segment_sentiments = lr_model.predict(text_tfidf)\n",
        "\n",
        "# Display the results\n",
        "print(\"Segment Text\\t\\tPredicted Sentiment\")\n",
        "for segment, predicted_sentiment in zip(content_array, segment_sentiments):\n",
        "    print(segment, \"\\t\\t\", predicted_sentiment)\n",
        "# Count variables for positive, negative, and neutral sentiments\n",
        "positive_count = 0\n",
        "negative_count = 0\n",
        "neutral_count = 0\n",
        "\n",
        "# Iterate through the predicted sentiments and count occurrences\n",
        "for sentiment in segment_sentiments:\n",
        "    if sentiment == 'positive':\n",
        "        positive_count += 1\n",
        "    elif sentiment == 'negative':\n",
        "        negative_count += 1\n",
        "    else:  # Neutral sentiment\n",
        "        neutral_count += 1\n",
        "\n",
        "# Print the counts\n",
        "print(\"Positive count:\", positive_count)\n",
        "print(\"Negative count:\", negative_count)\n",
        "print(\"Neutral count:\", neutral_count)\n"
      ],
      "metadata": {
        "id": "XsiXI5ntuAv-",
        "outputId": "b35dd915-24e4-4c3e-e2cf-4a8114fd5315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segment Text\t\tPredicted Sentiment\n",
            "Microsoft Co. (NASDAQ:MSFT) Receives Average Recommendation of “Moderate Buy” from Brokerages \t\t neutral\n",
            "Contrasting SilverSun Technologies (NASDAQ:SSNT) & Globant (NYSE:GLOB) \t\t positive\n",
            "G2 Capital Management LLC OH Cuts Stock Position in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) is Clarius Group LLC’s Largest Position \t\t neutral\n",
            "Hartford Financial Management Inc. Has $19.03 Million Stock Position in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) Shares Sold by Essex LLC \t\t neutral\n",
            "Meitav Investment House Ltd. Sells 69,223 Shares of Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "PLAYSTUDIOS, Inc. (NASDAQ:MYPS) to Post FY2024 Earnings of ($0.06) Per Share, Northland Capmk Forecasts \t\t neutral\n",
            "What Are Stock Buybacks? The Apple-Led Strategy Is Expected To Swell To $1 Trillion By 2025 \t\t neutral\n",
            "How Corporate America is rethinking its sustainability and diversity efforts \t\t neutral\n",
            "Glancy Prongay & Murray LLP Reminds Investors of Looming Deadline in the Class Action Lawsuit Against Perion Network Ltd. (PERI) \t\t neutral\n",
            "The Global AI Dilemma: How It Should Be Regulated \t\t neutral\n",
            "Why Duolingo (DUOL) Shares Are Plunging Today \t\t neutral\n",
            "Funko Appoints Cynthia Williams Chief Executive Officer, Board Member \t\t neutral\n",
            "Funko Reports First Quarter 2024 Financial Results; Reiterates Full-Year Outlook for 2024 \t\t neutral\n",
            "Magazine Luiza S A : Dados Econômico-Financeiros \t\t neutral\n",
            "Phil Spencer and the Battle for Xbox’s Soul \t\t neutral\n",
            "India's near 8% GDP growth isn't transforming into stock market returns. Here's why \t\t positive\n",
            "KeyCorp Increases Bandwidth (NASDAQ:BAND) Price Target to $32.00 \t\t positive\n",
            "Microsoft Co. (NASDAQ:MSFT) Shares Sold by Live Oak Private Wealth LLC \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) Shares Sold by Ycg LLC \t\t neutral\n",
            "Citizens National Bank Trust Department Acquires 167 Shares of Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "EMC Capital Management Cuts Stock Holdings in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Globant S.A. (NYSE:GLOB) Stake Lessened by Victory Capital Management Inc. \t\t neutral\n",
            "Acer Predator Orion 3000 review: Compact gaming PC power \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) Shares Sold by Xcel Wealth Management LLC \t\t neutral\n",
            "NewEdge Wealth LLC Has $198.19 Million Stake in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Microsoft's mystifying mismanagement | This Week in Business \t\t neutral\n",
            "Bandwidth (NASDAQ:BAND) Price Target Raised to $36.00 \t\t positive\n",
            "Kaye Capital Management Cuts Position in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "AlphaQ Advisors LLC Sells 2,295 Shares of Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Saxony Capital Management LLC Makes New $1.53 Million Investment in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Canaccord Genuity Group Raises Bandwidth (NASDAQ:BAND) Price Target to $40.00 \t\t neutral\n",
            "AvePoint (NASDAQ:AVPT) Reaches New 52-Week High After Strong Earnings \t\t positive\n",
            "Bandwidth (NASDAQ:BAND) PT Raised to $25.00 at Robert W. Baird \t\t neutral\n",
            "Simplicity Wealth LLC Purchases 3,677 Shares of Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Russell Investments Group Ltd. Purchases Shares of 437,302 AvePoint, Inc. (NASDAQ:AVPT) \t\t neutral\n",
            "Granite Bay Wealth Management LLC Grows Stock Holdings in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Capital Advisors Inc. OK Has $176.97 Million Position in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Bandwidth (NASDAQ:BAND) Price Target Increased to $28.00 by Analysts at Barclays \t\t positive\n",
            "Natixis Advisors L.P. Purchases 52,203 Shares of Infosys Limited (NYSE:INFY) \t\t neutral\n",
            "Harel Insurance Investments & Financial Services Ltd. Sells 3,811 Shares of Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Freedom Day Solutions LLC Has $6.48 Million Holdings in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Keene & Associates Inc. Has $4.03 Million Stock Holdings in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Charif Elansari Purchases 500,000 Shares of Dropsuite Limited (ASX:DSE) Stock \t\t neutral\n",
            "S. R. Schill & Associates Has $6.55 Million Stock Position in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Mn Services Vermogensbeheer B.V. Decreases Stake in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Windward Private Wealth Management Inc. Purchases New Shares in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "SHAREHOLDER ALERT: Pomerantz Law Firm Announces the Filing of a Class Action Against Perion Network Ltd. – PERI \t\t neutral\n",
            "Bragar Eagel & Squire, P.C. Reminds Investors That Class Action Lawsuits Have Been Filed Against QuidelOrtho, Perion, Doximity, and Sharecare and Encourages Investors to Contact the Firm \t\t neutral\n",
            "Bragar Eagel & Squire, P.C. Reminds Investors That Class Action Lawsuits Have Been Filed Against QuidelOrtho, Perion, Doximity, and Sharecare and Encourages Investors to Contact the Firm \t\t neutral\n",
            "PERI INVESTOR NOTICE: Robbins Geller Rudman & Dowd LLP Announces that Perion Network Ltd. Investors with Substantial Losses Have Opportunity to Lead Case \t\t neutral\n",
            "PERI INVESTOR NOTICE: Robbins Geller Rudman & Dowd LLP Announces that Perion Network Ltd. Investors with Substantial Losses Have Opportunity to Lead Case \t\t neutral\n",
            "Comparing Adaptive Biotechnologies (NASDAQ:ADPT) & Replimune Group (NASDAQ:REPL) \t\t neutral\n",
            "Globant (NYSE:GLOB) Cut to Sector Perform at Scotiabank \t\t negative\n",
            "4 tools for getting started with Lottie animation \t\t neutral\n",
            "Bezos, Zuckerberg lead Magnificent Seven insider stock sales \t\t neutral\n",
            "Marmo Financial Group LLC Boosts Stake in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Market Street Wealth Management Advisors LLC Grows Stake in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Strs Ohio Acquires 21,710 Shares of Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Cornercap Investment Counsel Inc. Grows Stock Position in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Bandwidth’s (BAND) “Hold” Rating Reiterated at Needham & Company LLC \t\t neutral\n",
            "Gozde Girisim Sermayesi Yatirim Ortakligi : 31.03.2024 Annual Report \t\t neutral\n",
            "Sierra Capital LLC Reduces Position in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "What Ever Happened to MapQuest? \t\t neutral\n",
            "Comparing Open Text (NASDAQ:OTEX) & Brand Engagement Network (NASDAQ:BNAI) \t\t neutral\n",
            "Dow Jones Futures Rise; Apple, Google Move On iPhone News; Nvidia Gets Price Target Hike \t\t neutral\n",
            "Microsoft Co. (MSFT) To Go Ex-Dividend on May 15th \t\t neutral\n",
            "The momentum keeps going \t\t neutral\n",
            "News Highlights: Top Global Markets News of the Day - Monday at 11 AM ET \t\t neutral\n",
            "S&P 500 edges down, investors and consumers wary of inflation \t\t neutral\n",
            "OpenAI gives a shoutout to Nvidia — plus, a new industrial stock joins our watchlist \t\t neutral\n",
            "2024’s Meme Stock Resurrection Adds More Than $500 Million To Fortunes Of These Two Billionaires \t\t neutral\n",
            "DEADLINE REMINDER: Faruqi & Faruqi, LLP Investigates Claims on Behalf of Investors of Perion Network \t\t neutral\n",
            "The creator of 'Magic: The Gathering' knows where it all went wrong \t\t neutral\n",
            "Vodafone : Full Year Presentation \t\t neutral\n",
            "PERI INVESTOR ALERT: Bronstein, Gewirtz & Grossman LLC Announces that Perion Network Ltd. Investors with Substantial Losses Have Opportunity to Lead Class Action Lawsuit! \t\t neutral\n",
            "Elmwood Wealth Management Inc. Lowers Stock Holdings in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Invesco LLC Trims Stake in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "LifePlan Financial LLC Makes New $1.98 Million Investment in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Flputnam Investment Management Co. Acquires 18,191 Shares of Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Links 5/14/2024 \t\t neutral\n",
            "Members Trust Co Lowers Holdings in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Sippican Capital Advisors Has $883,000 Stock Holdings in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "24/7 trading is already in full swing. Now Wall Street is considering ditching the opening and closing bells altogether \t\t neutral\n",
            "Datamatics Global Services : Transcript – Q4FY24 Earnings Call - 9 May 2024 \t\t neutral\n",
            "Stocks Edge Higher As Powell Responds To Inflation Data; GameStop Surges Again In Revived Meme Frenzy \t\t neutral\n",
            "Liberty All-Star Equity Fund April 2024 Monthly Update \t\t neutral\n",
            "Liberty All-Star® Growth Fund, Inc. April 2024 Monthly Update \t\t neutral\n",
            "Airlines Take Their Fight Against ‘Junk Fees’ To Court \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) Stock Holdings Raised by Marietta Wealth Management LLC \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) is SVB Wealth LLC’s 3rd Largest Position \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) Shares Acquired by Riverstone Advisors LLC \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) Stock Position Decreased by Imprint Wealth LLC \t\t neutral\n",
            "New York State Common Retirement Fund Has $490,000 Holdings in AvePoint, Inc. (NASDAQ:AVPT) \t\t neutral\n",
            "Hamilton Point Investment Advisors LLC Raises Holdings in Microsoft Co. (NASDAQ:MSFT) \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) is Desjardins Global Asset Management Inc.’s 2nd Largest Position \t\t neutral\n",
            "Microsoft Co. (NASDAQ:MSFT) Shares Sold by Octavia Wealth Advisors LLC \t\t neutral\n",
            "Bandwidth Inc. (NASDAQ:BAND) Insider Devin M. Krupka Sells 2,500 Shares \t\t neutral\n",
            "5 things to know before the stock market opens Wednesday \t\t neutral\n",
            "Positive count: 6\n",
            "Negative count: 1\n",
            "Neutral count: 93\n"
          ]
        }
      ]
    }
  ]
}